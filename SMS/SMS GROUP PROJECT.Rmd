---
title: "SMS PROJECT"
author: "TENG MAN"
date: "2023-01-23"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Dataset

The dataset is available in the kaggle,

https://www.kaggle.com/datasets/loveall/appliances-energy-prediction

# Case study and Data Description

## Case Study

All the data readings are taken at 10 mins intervals for 4.5 months. A ZigBee wireless sensor network was used to keep track of the house's temperature and humidity. About every 3.3 minutes, each wireless node sent the temperature and humidity conditions it was measuring. Then, the wireless data was averaged over 10 minute periods. m-bus energy metres were used to record the energy data every 10 minutes. The weather from the weather station at the closest airport, Chievres Airport in Belgium, was downloaded from a public data set on Reliable Prognosis (rp5.ru) and merged with the experimental data sets using the date and time column. Two random variables have been added to the data set so that regression models can be tested and non-predictive attributes can be removed (parameters).

## Goal

The goal is to predict the energy consumption of appliances using 29 characteristics. Utilizing Exploratory Data Analysis (EDA), Model Selection, Feature Selection, and Appropriate Transformation, the optimal model for predicting the energy consumption of home appliances is established.

## Table of Feature Description

|      | Feature    | Description                                                  |
| ---- | ---------- | ------------------------------------------------------------ |
| 1    | date       | time year-month-day hour:minute:second                       |
| 2    | lights     | energy use of light fixtures in the house in Wh              |
| 3    | T1         | Temperature in kitchen area, in Celsius                      |
| 4    | T2         | Temperature in living room area, in Celsius                  |
| 5    | T3         | Temperature in laundry room area                             |
| 6    | T4         | Temperature in office room, in Celsius                       |
| 7    | T5         | Temperature in bathroom, in Celsius                          |
| 8    | T6         | Temperature outside the building (north side), in Celsius    |
| 9    | T7         | Temperature in ironing room, in Celsius                      |
| 10   | T8         | Temperature in teenager room 2, in Celsius                   |
| 11   | T9         | Temperature in parents' room, in Celsius                     |
| 12   | T_out      | Temperature outside (from Chievres weather station), in Celsius |
| 13   | Tdewpoint  | from Chievres weather station, Â°C                           |
| 14   | RH_1       | Humidity in kitchen area, in %                               |
| 15   | RH_2       | Humidity in living room area, in %                           |
| 16   | RH_3       | Humidity in laundry room area, in %                          |
| 17   | RH_4       | Humidity in office room, in %                                |
| 18   | RH_5       | Humidity in bathroom, in %                                   |
| 19   | RH_6       | Humidity outside the building (north side), in %             |
| 20   | RH_7       | Humidity in ironing room, in %                               |
| 21   | RH_8       | Humidity in teenager room 2, in %                            |
| 22   | RH_9       | Humidity in parents' room, in %                              |
| 23   | RH_out     | Humidity outside (from Chievres weather station), in %       |
| 24   | Pressure   | from Chievres weather station, in mm Hg                      |
| 25   | Wind speed | from Chievres weather station, in m/s                        |
| 26   | Visibility | from Chievres weather station, in km                         |
| 27   | Rv1        | Random variable 1, non-dimensional                           |
| 28   | Rv2        | Random variable 2, non-dimensional                           |
| 29   | Appliances | Total energy used by appliances, in Wh                       |



We use Python pandas to preprocess the dataset, then save it into a new file at the same directory as original dataset, see appendix.



# Loading Data

```{r}
data = read.csv('KAG_energydata_detailed.csv')
data$date = NULL
data$X = NULL
data
```

# Correlation Analysis

We see that humidity and temperature among different features are heavily correlated. Then we can take the average of these to reduce the features.

```{r,fig.height=15, fig.width=15}
library("png")
pp <- readPNG("correlation_matrix.png")
plot.new() 
rasterImage(pp,0,0,1,1)
```
Picture above is obtained using Python `seaborn` and `pd.DataFrame.cor`. The calculation of VIF below shows that temperature and humidty themselves are highly correlated.

```{r}
library(car)
vif(lm(energy.use.in.Wh ~ ., data))
```

# Simple Aggregration of confounded group of same unit
As we prefer parsimony model and the model is multiple linear, we aggregate the confounded variables but of same unit into one variable. In this case, we take the mean.
```{r}
humid = c('Humidity.in.bathroom', 'Humidity.in.ironing.room', 'Humidity.in.kitchen.area', 'Humidity.in.laundry.room.area', 'Humidity.in.living.room.area', 'Humidity.in.office.room', 'Humidity.in.parents.room', 'Humidity.in.teenager.room.2', 'Humidity.outside', 'Humidity.outside.the.building..north.side.')

temp = c('Temperature.in.bathroom', 'Temperature.in.ironing.room', 'Temperature.in.kitchen.area', 'Temperature.in.laundry.room.area', 'Temperature.in.living.room.area', 'Temperature.in.office.room', 'Temperature.in.parents.room', 'Temperature.in.teenager.room.2', 'Temperature.outside.the.building..north.side.', 'T_out')

data$average_humdity = apply(data[,humid],1, mean)

data$average_temperature = apply(data[,temp],1, mean)
data[,humid] = NULL
data[,temp] = NULL
```

# EDA - Data distribution via Histogram

We see that temperature, pressure, dewpoint and humidity are roughly normally distributed whereas windspeed doesn't. Ideally, the data should be normally distributed, but some deviate is not a big problem.

```{r}
for(col in names(data)){
  hist(data[,col], main=col)
}
```

# EDA - Scatter plot with Regression Line

The linear relation is not obvious among the predictor variables with the target variable except the energy use of light fixtures.
```{r}
ys = data$energy.use.in.Wh
for(col in names(data)[2:ncol(data)]){
  xs = data[,col]
  plot(xs,ys, main=col)
  abline(lm(ys ~ xs))
}
```

# Multiple Linear Regression

## First Attempt - Residual Analysis

We started with the simplest multiple linear regression and follow by residual analysis. We see that the residual points deviate out from the line uniformly which implies the problem of variance and also the residuals are not normally distributed.
```{r}
mlr = lm(energy.use.in.Wh ~ ., data)
plot(mlr)
```


## Normalization via Box-cox transformation

We carry out box-cox transformation to determine the best transformation that will might fix the un-normality of residuals.  The best lambda value we get is near to -0.5 which corresponds to inverse square root transformation.
```{r}
library(MASS)
res = boxcox(mlr, plotit=T)
idx = which(res$y == max(res$y))
lambda = res$x[idx]
lambda
```

As previously, we apply inverse square root to normalize the target value. The histogram is now near to a bell-curve shape (i.e.: normalized value)
```{r}
xs = data$energy.use.in.Wh
hist(1/sqrt(xs))
```

## Apply box-cox transformation

We fit the model that have been transformed. The qq-plot of residuals scatter around the line but closer than in previous model. The regularity and  funnel shape in residual vs fitted plot imply that decreasing variance as original target value getting bigger (i.e.: smaller transformed value). From residuals vs leverage plot, there are only few leverage points (i.e.: labelled points).

```{r}
mlr = lm(1/sqrt(energy.use.in.Wh) ~ ., data)
plot(mlr)
```

# Feature Selection via stepAIC

In bias to simpler model, we wish our model is parsimony, then we want to select the best feature subset while maintaining model performance (i.e.: by AIC criterion). Since brute force takes a lot time, we use step-wise algorithm to get the sub optimal feature subset. In short, the function `stepAIC` will choose the best subset. 

Based on the summary and anova result, we see all features are significant in predicting the amount of energy consumed.

```{r}
best_mlr = stepAIC(mlr,trace=F)
summary(best_mlr)
anova(best_mlr)
```
# Multicollinearity

We calculate the variance inflation factor (VIF) to investigate the multicollinearity. If the VIF value is greater than 5, it is an alarming sign that the variable is highly correlated with other variable. The result doesn't surprise us that dewpoint, humidity and temperature are closely correlated. We didn't aggregate them in earlier section because the aggregated value are of the same unit whereas humidity, viewpoint and temperature are not of same unit, then we decided kept them as they are.

```{r}
vif(best_mlr)
```


# Best Multiple Linear Regression Model

This is the best model as we have done via aggregating confounded variable, stabilize the variance via box-cox transformation and feature selection.

$$
    \frac{1}{\sqrt{y_\text{energy}}} = x_\text{light fixtures} + x_\text{pressure} +  x_\text{visibility} + x_\text{dewpoint} + x_\text{humidity} +  x_\text{temperature}
$$

# Alternative and Limitation

We could use decision tree which is not the main focus of statistical modelling for our project but it should worth a try. This is because the residual plots are not ideal where constant variance and autocorrelation are not met. Since the data is indeed temporal and measured continuously, it is susceptible to autocorrelation but the test is not carry here.


# Business Solution

Considering the decarbonization movement is a trend, we may corporate model into an app to fulfill the need of measuring appliances' energy efficiency. The app will receive sensor data from surrounding smart devices and online to estimate the energy used. Suppose the smart devices themselves can measure the energy used, then if there is a deviate between model prediction and smart devices, then it will warn an anomaly found. This is an example of how it can be applied in industry. 

```{r, fig.height=8, fig.width=4}
library("png")
pp <- readPNG("dte_app.png")
plot.new() 
rasterImage(pp,0,0,1,1)
```


